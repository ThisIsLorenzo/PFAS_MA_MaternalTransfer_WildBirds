---
title: "Maternal PFAS transfer in wild birds: a systematic review and meta-analysis"
author: "L.Ricolfi"
date: '2022-06-28'
output: html_document
editor_options: 
  chunk_output_type: console
---

# Project title

*Maternal PFAS transfer in wild birds: a systematic review and meta-analysis*

# Research questions

1.  What is the overall maternal PFAS transfer (i.e., the ratio between PFAS concentration in both eggs and hatchling and the adult female) in wild birds, and how variable is it?

2.  Do physicochemical properties of PFAS compounds affect the maternal transfer efficiency in wild birds? Specifically, is the maternal transfer mediated by a compounds':

-   carbon chain length?
-   functional group?
-   molecular weight?

3.  Do biological factors of birds affect the maternal PFAS transfer efficiency? Specifically, is the maternal transfer mediated by:

-   feeding ecology or trophic position?
-   birds' body weight?
-   average clutch size?
-   average number of broods per year?
-   egg mass?
-   the type of adult bird's tissue analysed?
-   the type of egg's part or chick's tissue analysed?
-   the developmental stage of the offspring (i.e., chick vs egg)?

# Objectives

1.  Quantify the overall meta-analytic mean of maternal transfer ratio (i.e., Coffspring/Cfemale) and its variation.

2.  Identify and evaluate sources of heterogeneity related to PFAS properties:

-   Assess whether different types of PFAS have different transfer rates.
-   Estimate the variance explained for different carbon chain lengths, functional groups, and molecular masses of PFAS.

3.  Identify and evaluate sources of heterogeneity related to biological samples:

-   Assess whether the proportion of maternal transfer is statistically different between seabirds and non-seabirds.
-   Estimate the variance explained for different feeding ecology, body mass, the average number of eggs in a clutch, the average number of broods per year, egg mass, type of adult bird's tissue analysed, type of egg's part analysed, and developmental stage of the progeny.

# Purpose

This .Rmd document provides the code I used for data processing, data analysing, and visualizations.

# Data model

A relational data model organizes extracted data from included studies into tables of rows and columns, and the relationships between the tables are defined using primary and foreign keys. This allows for efficient querying and data manipulation, and makes it easy to integrate data from multiple tables.

The six data tables are listed as follow:

-   **study_info:** data related to the study such as the year of publication and

-   **species_info**

-   **pfas_info**

-   **cohort_info**

-   **sample_info**

-   **measurements**

They are stored in [a repository on GitHub](https://github.com/ThisIsLorenzo/PFAS_MA_MaternalTransfer_WildBirds_Pilot/tree/main/Data)

# Data loading & processing

Set up knitr options:

```{r setup, eval = TRUE, include = TRUE, message = FALSE, echo = TRUE,  warning = FALSE}
knitr::opts_chunk$set(
  message = FALSE, #turning off the display of messages
  warning = FALSE,#turning off the display of warnings
  tidy = TRUE, #turning on the "tidy" option (which affects the formatting of code chunks)
  cache = TRUE, #turning on caching (so that code chunks are only executed if their dependencies have changed)
  echo=TRUE #turning on the "echo" option (so that code is displayed in the output)
)

rm(list = ls()) #Effectively clears the environment of any data, functions, or variables that have been defined
```

loading packages:

```{r loading packages, results = 'hide'}
# using the pacman package to load multiple packages at once
pacman::p_load(tidyverse, #a collection of packages for data manipulation, visualization, and modeling, including packages like dplyr, ggplot2, and tidyr
               readr, #a package for reading and writing tabular data, such as CSV files
               ape, #a package for analyzing phylogenetics and evolutionary data
               curl, #a package for transferring data over the internet using various protocols, such as HTTP and FTP
               rotl, #a package for working with phylogenetic trees, including functions for manipulating and visualizing trees
               RColorBrewer, #a package for generating color palettes for plotting
               here, #a package for working with file paths, particularly when working with project-based workflows
               dm, #a package for working with distance matrices
               dplyr, #a package for data manipulation, which is already included in the tidyverse package
               metafor, #a package for conducting meta-analyses
               meta, #a package for conducting meta-analyses
               forestplot, #a package for creating forest plots, which are commonly used to display the results of meta-analyses
               orchaRd, #a package for working with ordination data
               kableExtra, #a package for creating tables and formatting them in R Markdown documents
               phytools, #a package for phylogenetic comparative biology
               patchwork, #a package for combining multiple plots into a single figure
               clubSandwich, #a package for variance estimation and hypothesis testing in clustered data
               MuMIn #a package for model selection and multimodel inference
               )
```

loading the six data tables:

```{r loading data, results = 'hide'}
st <- read_csv(here("Data", "study_info.csv"))
sp <- read_csv(here("Data", "species_info.csv"))
pfas <- read_csv(here("Data", "pfas_info.csv"))
co <- read_csv(here("Data", "cohort_info.csv"))
sa <- read_csv(here("Data", "sample_info.csv"))
me <- read_csv(here("Data", "measurement_info.csv"))
```

cleaning data:

```{r cleaning data tables, results = 'hide'}
st <- st %>% 
  select(-("Timestamp")) %>% #removing the timestamp column
  select(-(ends_with("comment"))) #removing any column ending with comment
sp <- sp %>% 
  select(-("Timestamp")) %>%
  select(-(ends_with("comment")))
pfas <- pfas %>% 
  select(-("Timestamp")) %>% 
  select(-(ends_with("comment")))
pfas <- pfas %>% 
  dplyr::mutate(functional_group = ifelse(functional_group == "Carboxylic acid", "Carboxylate / carboxylic acid", functional_group)) #checking if the value of the "functional_group" column is equal to "Carboxylic acid". If it is, then the new "functional_group" column is assigned the value "Carboxylate / carboxylic acid". If not, the original value of the "functional_group" column is used
co <- co %>% 
  select(-("Timestamp")) %>%
  select(-(ends_with("comment")))
sa <- sa %>% 
  select(-("Timestamp")) %>% 
  select(-(ends_with("comment")))
me <- me %>%
  select(-("Timestamp")) %>% 
  select(-(ends_with("comment")))

co$laying_order[co$laying_order == "mixed"] <- NA #assigning NA if laying order is mixed
co$laying_order <- as.numeric(co$laying_order) #turning laying order as numeric

#removing characters from carbon chain length and molecular weight. Making them as numeric.
pfas$carbon_chain_length[pfas$carbon_chain_length == "mixed"] <- NA
pfas$carbon_chain_length <- as.numeric(pfas$carbon_chain_length)

pfas$molecular_weight[pfas$molecular_weight == "mixed"] <- NA
pfas$molecular_weight <- as.numeric(pfas$molecular_weight)
```

create dm object without keys:

```{r adding tables to the dm object, results = 'hide'}
data_dm_no_keys <- dm(st, sp, pfas, co, sa, me)
data_dm_no_keys
data_dm_no_keys$st
data_dm_no_keys[c("st", "co")]
```

defining primary keys:

```{r defining primary keys, results = 'hide'}
data_dm_only_pks <- data_dm_no_keys %>% 
  dm_add_pk(table = st, columns = study_ID) %>% 
  dm_add_pk(sp, species_ID) %>% 
  dm_add_pk(pfas, pfas_ID) %>% 
  dm_add_pk(co, cohort_ID) %>% 
  dm_add_pk(sa, sample_ID) %>% 
  dm_add_pk(me, measurement_ID)
data_dm_only_pks
```

defining foreign keys:

```{r defining foreign keys, results = 'hide'}
data_dm_all_keys <- 
  data_dm_only_pks %>% 
  dm_add_fk(table = co, columns = study_ID, ref_table = st) %>% 
  dm_add_fk(table = co, columns = species_ID, ref_table = sp) %>%
  dm_add_fk(table = sa, columns = cohort_ID, ref_table = co) %>%
  dm_add_fk(table = me, columns = sample_ID, ref_table = sa) %>%
  dm_add_fk(table = me, columns = pfas_ID, ref_table = pfas)
data_dm_all_keys
```

dm visualization and integrity check:

```{r visualization, eval=FALSE}
data_dm_all_keys %>% 
  dm_draw()

data_dm_all_keys %>% 
  dm_examine_constraints()
# â„¹ All constraints satisfied.
```

The following chunk creates a new table that merges sa, co, and me. me includes only the variables we need to calculate effect sizes (i.e., min, max, median, etc. are removed)

```{r moving columns among dm objects}
me1 <- 
  data_dm_all_keys %>% 
  dm_select(me, measurement_ID | group_info | sample_ID | pfas_ID | mean_arithmetic | SD | n | limit_type) %>% 
  dm_select(sa, sample_ID : sample_type) %>% 
  dm_select(co, cohort_ID : data_pooled) %>% 
  dm_select(pfas, pfas_ID) %>% 
  dm_select(sp, species_ID) %>% 
  dm_select(st, study_ID) %>% 
  dm_flatten_to_tbl(.start = me, .recursive = TRUE, .join = left_join)

colnames(me1)
```


The follwoing chunck create a new column called "es_ID" which matches all the pairs of measurement for effect size calculation.
Study ID, PFAS ID, specie ID, and sampling location must be the same. The group (i.e., group_info) must be different, so that we pair adult-progeny in all possible combinations (different tissues in adults, eggs, chicks).

```{r}
list_dat <- 
  me1 %>% 
  dplyr::group_split(study_ID,
                  pfas_ID , 
                  species_ID,
                  sampling_location) #grouping me1 using the variables we want to be the same between adult and progeny

wide_table <-
  function(dat)
    { #defining wide_table function

dat <-
  as.data.frame(dat) #converting to a data frame
  
adult <-
  dat[dat$group_info == "adult", 1] #creating the new adult variable
progeny <-
  dat[dat$group_info == "progeny", 1] #creating the new progeny variable

ids <-
  expand.grid(adult_id = adult,
              progeny_id = progeny) #creating a new variable called "ids" which is a grid of all possible combinations of "adult_id" and "progeny_id"

adult_id <- ids[[1]] #assigning the first column of the "ids" variable respectively
progeny_id <- ids[[2]]

pos_adult <- match(adult_id, dat$measurement_ID)
adult_dat <- dat[pos_adult, ] #using the match() function to find the positions of "adult_id" and "progeny_id" in the "measurement_ID" column of the data, and creates new variables "adult_dat" and "progeny_dat" respectively, which are subsets of the data at those positions

pos_progeny <- match(progeny_id, dat$measurement_ID)
progeny_dat <- dat[pos_progeny, ]

ndat <- data.frame(
           measurement_ID_A = adult_dat[["measurement_ID"]],
           measurement_ID_P = progeny_dat[[ "measurement_ID"]],
           mean_arithmetic_A = adult_dat[["mean_arithmetic"]],
           mean_arithmetic_P =  progeny_dat[[ "mean_arithmetic"]],
           SD_A = adult_dat[["SD"]],
           SD_P = progeny_dat[["SD"]],
           n_A = adult_dat[["n"]],
           n_P = progeny_dat[["n"]],
           life_stage_A = adult_dat[["life_stage"]],
           life_stage_P = progeny_dat[["life_stage"]],
           study_ID_A = adult_dat[["study_ID"]],
           study_ID_P = progeny_dat[["study_ID"]],
           species_ID_A = adult_dat[["species_ID"]],
           species_ID_P = progeny_dat[["species_ID"]],
           sample_type_A = adult_dat[["sample_type"]],
           sample_type_P = progeny_dat[["sample_type"]],
           sampling_location_A = adult_dat[["sampling_location"]],
           sampling_location_P = progeny_dat[["sampling_location"]],
           pfas_ID_A = adult_dat[["pfas_ID"]],
           pfas_ID_P = progeny_dat[["pfas_ID"]],
           limit_type_A = adult_dat[["limit_type"]],
           limit_type_P = progeny_dat[["limit_type"]],
           sampling_year_A = adult_dat[["sampling_year"]],
           sampling_year_P = progeny_dat[["sampling_year"]],
           sampling_month_A = adult_dat[["sampling_month"]],
           sampling_month_P = progeny_dat[["sampling_month"]],
           developmental_stage_A = adult_dat[["developmental_stage"]],
           developmental_stage_P = progeny_dat[["developmental_stage"]],
           breeding_stage = adult_dat[["breeding_stage"]],
           laying_order = progeny_dat[["laying_order"]],
           nest = adult_dat[["nest"]],
           body_weight_mean = adult_dat[["body_weight_mean"]],
           body_weight_sd = adult_dat[["body_weight_sd"]],
           egg_weight_mean = progeny_dat[["egg_weight_mean"]],
           egg_weight_sd = progeny_dat[["egg_weight_sd"]],
           data_pooled = adult_dat[["data_pooled"]]
             ) #creating a new data table "ndat" that contains columns for all of the relevant variables from both "adult_dat" and "progeny_dat", with columns for adult data having the suffix "_A" and columns for progeny data having the suffix "_P"
ndat

}


dat <- list_dat[[3]] #selecting the third subset of the grouped data (list_dat[[3]]) and passes it to the wide_table() function, saving the result to a new variable "res"

res <- wide_table(list_dat[[3]])
res

ntable <- map_dfr(list_dat, wide_table) #applying wide_table data to every item in this list
```

Create effect sizes column and tidy data

```{r}
ntable <- dplyr::mutate(ntable, 
                        es_ID = as.vector(001 : 412)) #creating esID column
ntable$es_ID <-  sub("(.{1})", "es_\\1", ntable$es_ID) #creating es_IDs

#the following columns are created in order to link the new ntable to the dm object
ntable <- dplyr::mutate(ntable, 
                        study_ID =  ntable$study_ID_A) #adding study_ID column
ntable <- dplyr::mutate(ntable,
                        species_ID =  ntable$species_ID_A) #adding species_ID column
ntable <- dplyr::mutate(ntable,
                        pfas_ID =  ntable$pfas_ID_A) #adding pfas_ID column

ntable <- dplyr::select(ntable, -c('study_ID_A', 
                                   'study_ID_P', 
                                   'species_ID_A', 
                                   'species_ID_P', 
                                   'pfas_ID_A',
                                   'pfas_ID_P')) #removing redundant columns
```

Remove effect sizes where both adult and progeny concentrations were under the limit of detection or quantification. This was an assumption made in the pre-registration. This is necessary to have meaningful response ratios.

```{r}
ntable <- 
  ntable %>% 
  dplyr::filter(is.na(limit_type_A) == "TRUE" |
               is.na(limit_type_P) == "TRUE")
```

Remove effect size measurements with NA in the mean concentration in the adult OR progeny. This is necessary for successful analysis because means cannot be "NA" in effect size calculations.

```{r}
ntable <- 
  ntable %>% 
  dplyr::filter(is.na(mean_arithmetic_A) == "FALSE" &
                  is.na(mean_arithmetic_P) == "FALSE")
```

#DM object

Rebuilt the dm object with the new ntable.

```{r adding the ntable to the dm object, include=FALSE}
nt <- ntable
data_dm_no_keys <- dm(st, sp, pfas, nt)

data_dm_only_pks <- data_dm_no_keys %>%
  dm_add_pk(table = st, columns = study_ID) %>%
  dm_add_pk(sp, species_ID) %>%
  dm_add_pk(pfas, pfas_ID) %>%
  dm_add_pk(nt, es_ID)
data_dm_only_pks

data_dm_all_keys <-
  data_dm_only_pks %>%
  dm_add_fk(table = nt, columns = study_ID, ref_table = st) %>% 
  dm_add_fk(table = nt, columns = species_ID, ref_table = sp) %>% 
  dm_add_fk(table = nt, columns = pfas_ID, ref_table = pfas)
data_dm_all_keys
```

```{r, eval=FALSE}
data_dm_all_keys %>% 
  dm_draw()

data_dm_all_keys %>% 
  dm_examine_constraints()
```

Merging the dm tables in a wide table.

```{r merging all tables into one big table}
nt <-
  data_dm_all_keys %>%
  dm_flatten_to_tbl(.start = nt, .recursive = TRUE)
nt
```

# Forumulas

To assess the transfer of PFAS from mothers to their offspring, we used the logarithm of response ratio (lnRR) as our effect size, an approach initially proposed by Hedges et al. (1999) and later developed by Lajeunesse (2011) and Senior et al. (2020). The point and variance estimates for lnRR and v(lnRR) can be expressed as follows:

$$
\ln{\text{RR}} = \ln \left( \frac{m_{T}} {m_{C}}\right) + 
\frac{1}{2} \left(\frac{\text{CV}_T^2} {n_{T}} - \frac{\text{CV}_C^2} {n_{C}}\right)
$$

$$
v(\ln{\text{RR}}) = \frac{\text{CV}_T^2} {n_{T}} + \frac{\text{CV}_C^2} {n_{C}} - 2r_{TC}\frac{\text{CV}_T \text{CV}_C}{\sqrt{n_Cn_T}}
$$ $n_{T} = n_{C} = n$

where mT and mC are the sample means for the treatment (progeny) and control (adults) groups, respectively, nT and nC are the sample sizes for the two groups and CV is the coefficient of variation; that is, CVC = sdT /mT and CVC = sdC/mC, with sd being the (sample) standard deviation.

For obvious reasons, all our included studies used independent 2-group design. Thus, we set rTC = 0.

$$
v(\ln{\text{RR}}) = \frac{\text{CV}_T^2} {n_{T}} + \frac{\text{CV}_C^2} {n_{C}}
$$

Spake and Doncaster (2017) showed that sampling variance estimates that include sample standard deviation are likely to be downwardly biased when sample sizes (n) are small (n \< 50). Our sample sizes (n) per effect size were between 1 and 38, with the average of 24.3. *these values are PROBABLY WRONG* - Should I use N_tilde (min, max, mean)? The use of the averaged CV was shown to reduce the bias identified by Doncaster and Spake (2017).

Accordingly, we used:

$$
\ln{\text{RR}} = \ln \left( \frac{m_{T}} {m_{C}}\right) + 
\frac{1}{2} \left(\frac{\sum_{i=1}^{k}{\text{CV}_{Ti}^2}/k} {n_{T}} - \frac{\sum_{i=1}^{k}{\text{CV}_{Ci}^2}/k} {n_{C}}\right)
$$
$$
v(\ln{\text{RR}})= \frac{\sum_{i=1}^{k}{\text{CV}_{Ti}^2}/k} {n_{T
}} + \frac{\sum_{i=1}^{k}{\text{CV}_{Ci}^2}/k} {n_{C}}
$$

where k is the number of effect sizes (or studies) and the other symbols are the same as the above.

# Functions

The `lnRR_func` function is here used to calculate a log response ratio (lnRR) adjusted for small sample sizes. In addition, this formula accounts for correlated samples. For more details, see *Doncaster and Spake (2018) Correction for bias in meta-analysis of little-replicated studies. Methods in Ecology and Evolution; 9:634-644*

lnRR (point estimate) and var_nlRR ([sampling] variance estimate) forumulas are from Hedges et al. (1999) and subsequently extended by Lajeunesse (2011) and Senior et al. (2020).

```{r function to calculate effect size}
#Changing columns names to make them shorter
colnames(nt)[3] <- "mean_A"
colnames(nt)[4] <- "mean_P"
colnames(nt)[5] <- "sd_A"
colnames(nt)[6] <- "sd_P"

# Custom function to calculate the lnRR 
lnRR_func <- function(mean_A,
                      n_A,
                      mean_P,
                      n_P,
                      aCV2a,
                      aCV2p)
  {
  lnRR <- log(mean_P/mean_A) + 0.5 * ((aCV2p/n_P) - (aCV2a/n_A))	
  
  lnRR
  }
# Custom function to calculate the lnRR's sampling variance from independent designs (rTC = 0)
var_lnRR_ind <- function(mean_A,
                         n_A,
                         mean_P, 
                         n_P, 
                         aCV2a, 
                         aCV2p)
  {
  
  var_lnRR <- (aCV2a/n_A) + (aCV2p/n_P) 
  
  var_lnRR
  }
# mean_A: Concentration of PFAS in the adult sample
# n_A: Sample size of the adult sample
# mean_P: Concentration of PFAS of the progeny sample
# n_P: Sample size of the progeny sample 
# aCV2a: Mean coefficient of variation of the adult samples
# aCV2p: Mean coefficient of variation of the progeny samples

```

# Phylogenetic information

Import phylogenetic information and calculate phylogenetic variance-covariance matrix

NOTE: The phylogenetic tree was generated in the `tree_MA_MT_PFAS.Rmd` document

```{r}
tree <- read.tree(here("R", "phylogenetic_tree.tre")) # Import phylogenetic tree (see tree_MA_MT_PFAS.Rmd for more details) 
tree <- compute.brlen(tree) # Generate branch lengths 
cor_tree <- vcv(tree,corr = T) # Generate phylogenetic variance-covariance matrix 

nt2 <- nt

nt2$Phylogeny <- as.factor(str_replace(nt2$species_scientific_name, " ", "_")) # Add the `phylogeny` column to the data frame
colnames(cor_tree) %in% nt2$Phylogeny # Check correspondence between tip names and data frame

# Rename species names that do not match
levels(nt2$Phylogeny)[levels(nt2$Phylogeny) == "Larus_audouinii"] <- "Ichthyaetus_audouinii"
levels(nt2$Phylogeny)[levels(nt2$Phylogeny) == "Phalacrocorax_aristotelis"] <- "Gulosus_aristotelis"
levels(nt2$Phylogeny)[levels(nt2$Phylogeny) == "Diomedea_immutabilis"] <- "Phoebastria_immutabilis"

# checking all species are in the data
match(unique(nt2$Phylogeny), colnames(cor_tree))
match(nt2$Phylogeny, colnames(cor_tree))
```

```{r, eval=FALSE, fig.height=10, fig.width = 8}
# plotting tree
plot(tree)
```

# Effect sizes calculation

A meta-analysis combines the results of multiple studies to estimate the overall effect size, which represents the magnitude of a difference or the strength of a relationship. The effect size is the response variable in a meta-analytic model and can be measured using different metrics. The choice of metric is based on the research question being addressed. We use the log response ratio (lnRR; aka ratio of means), which is a measure of effect size that quantifies the difference in statistics between two groups.

## Averaged coefficient of variation

We follow the methods proposed by Nakagawa et al., 2022 ([A robust and readily implementable method for the meta-analysis of response ratios with and without missing standard deviations](https://ecoevorxiv.org/repository/view/3753/) to calculate the averaged coefficient of variation across studies.

We will first calculate the between study CV using the `cvg_avg` function. Here, we need to do this for the adults and progeny groups as follows, such that variable b_CV_1 and b_CV_2 are the averages for the adults and progeny groups, respectively. Then, we calculate the average between study CV, which will replace missing values.

```{r, eval=FALSE}
#How many missing sd values?
count(nt2, sd_A == "NA")
#   sd_A == "NA"   n
# 1        FALSE 317
# 2           NA  54
count(nt2, sd_P == "NA")
#   sd_P == "NA"   n
# 1        FALSE 290
# 2           NA  81
```

```{r}
cv_avg <- function(x, #mean values
                   sd, #standard deviation values
                   n, #sample size values
                   group, #variable to group the data by
                   data, #data table to use
                   label = NULL, #label the new columns in the data table
                   sub_b = TRUE, #whether or not to keep only the columns with "b_" in their names
                   cv2=FALSE) #whether or not to calculate the squared coefficient of variation
  {

# Check if the name is specified or not. If not, then assign it the name of the mean, x, variable input in the function. https://stackoverflow.com/questions/60644445/converting-tidyeval-arguments-to-string
  
if(is.null(label)){
  label <- purrr::map_chr(enquos(x), rlang::as_label)
} #checking if the "label" variable is null, and if so, creates a new variable "label" which is a list of the labels of the variables passed as arguments using the purrr and rlang packages
  
weighted_CV <- function(sd, x, n, cv2=FALSE){
  if(cv2){
    weighted.mean(na_if((sd / x)^2, Inf), n, na.rm = TRUE)
  }else{
    weighted.mean(na_if((sd / x), Inf), n, na.rm = TRUE)^2
  }
} #nested function called "weighted_CV" that calculates the weighted CV based on the values of sd, x, and n, and whether cv2 is true or false

# Calculate between study CV. Take weighted mean CV within study, and then take a weighted mean across studies of the within study CV. Weighted based on sample size and pooled sample size.
  b_grp_cv_data <- nt %>%
    dplyr::group_by({{group}}) %>% #grouping by group variable
    dplyr::mutate(w_CV2 = weighted_CV({{sd}}, 
                                         {{x}}, 
                                         {{n}},
                                         cv2=cv2),
                     n_mean = mean({{n}}, na.rm = TRUE)) %>% #calculating the weighted CV2 using the nested function and calculating the mean of the sample size variable
    dplyr::ungroup(.) %>% #ungrouping
    dplyr::mutate(b_CV2 = weighted.mean(w_CV2,
                                        n_mean,
                                        na.rm = TRUE), .keep = "used") # calculating the between-study CV2 by taking a weighted mean of the within-study CV2

# Make sure that label of the calculated columns is distinct from any other columns
  names(b_grp_cv_data) <- paste0(names(b_grp_cv_data), "_", label) #renaming the columns by appending "_label" to them

# Append these calculated columns back to the original data and return the full dataset.
  if(sub_b){
    b_grp_cv_data <- b_grp_cv_data %>% 
      dplyr::select(grep("b_", names(b_grp_cv_data)))
    dat_new <- cbind(data, b_grp_cv_data)
  } else {
    dat_new <- cbind(data, b_grp_cv_data)
  }

  return(data.frame(dat_new))
} #keeping only the columns with "b_" in their names, or keeping all columns, and binding the calculated columns back to the original data and returning the full dataset
  
# Calculate the average between study CV, which will replace missing values
nt2 <- cv_avg(x = mean_A,
             sd = sd_A,
             n = n_A,
             group = study_ID,
             label = "1",
             data = nt2) #using the cv_avg function to calculate the average between-study CV of the mean and standard deviation values of adult and progeny measurements by passing the appropriate variables and data table (nt2) as arguments, and saves the results to the same data table (nt2)

nt2 <- cv_avg(x = mean_P,
             sd = sd_P,
             n = n_P,
             group = study_ID,
             label = "2",
             data = nt2)
```

## lnRR and variance calculations

```{r Calculating lnRR and Variance}
# Calculate the squared coefficient of variation for adult and progeny groups. This part of the chunk has been called out as we have already estimated aCV2a and aCV2p in the previous chunk.

# aCV2 <- nt2 %>%
#   group_by(study_ID) %>%
#   summarise(CV2a = mean((sd_A/mean_A)^2, na.rm = T),
#             CV2p = mean((sd_P/mean_P)^2, na.rm = T)) %>%
#   ungroup() %>% # ungroup
#   summarise(aCV2a = mean(CV2a, na.rm = T), # Mean CV^2 for adult and progeny groups across studies
#             aCV2p = mean(CV2p, na.rm = T))

lnRR <- lnRR_func(mean_A = nt2$mean_A,
                  n_A = nt2$n_A,
                  mean_P = nt2$mean_P,
                  n_P = nt2$n_P,
                  aCV2a = nt2$b_CV2_1,
                  aCV2p = nt2$b_CV2_2)

var_lnRR <- var_lnRR_ind(mean_A = nt2$mean_A,
                         n_A = nt2$n_A,
                         mean_P = nt2$mean_P,
                         n_P = nt2$n_P,
                         aCV2a = nt2$b_CV2_1,
                         aCV2p = nt2$b_CV2_2) 
```

## Effective sample size (N_tilde) and its standard error calculations

These calculations will be used later on in the publication bias analyses. The harmonic mean is used instead of the simple average of the two sample sizes because it gives more weight to the smaller sample size, which can help to reduce the potential for bias in the meta-analysis.

```{r}
dat <- nt2 %>% 
  dplyr::mutate(N_tilde = (n_A*n_P)/(n_A + n_P)) # getting effective sample size calculating the harmonic mean of the two sample sizes. 

dat$ess.se <- sqrt(dat$N_tilde) # calculate adapted sampling error based on effective size - tilde square root n

dat <- cbind(dat, lnRR, var_lnRR) # Merge effect sizes with the data frame
```

## Variance-covariance matrix

Now, we need to account for correlated errors (i.e. effectively dividing the weight of the correlated estimates by half) because some effect sizes share the same control(adult). The multilevel model we will propose (Choosing a meta-analytical model) only deals with cases of non-independence among effect sizes. For non-independence among sampling variances (Î½i), for example, due to shared control statistics, we can construct a variance-covariance matrix to explicitly capture the non-zero covariance that arises from correlation between sampling errors (Î½i) within the same primary studies.

For this purpose, I calculate the variance-covariance from the log response ratio variance. Variance-covariance is a measure of how two random variables are related. The variance-covariance matrix is a square matrix that shows the variances and covariances of a set of random variables. The diagonal elements of the matrix show the variances of the individual random variables, while the off-diagonal elements show the covariances between pairs of variables.

```{r}

VCV_lnRR <- impute_covariance_matrix(dat$var_lnRR,
                                     cluster = dat$measurement_ID_A, 
                                     r = 0.5)

# Making the same in a data set without albumen (as it brings strong heterogeneity)

dat_noalbumen <-  dat %>% 
  dplyr::filter(sample_type_P != "albumen")

VCV_lnRR_noalbumen <- impute_covariance_matrix(dat_noalbumen$var_lnRR,
                                     cluster = dat_noalbumen$measurement_ID_A, 
                                     r = 0.5)

```

# Sensitivity analysis - Data

Here I create three data sets to run a sensitivity analysis. The first data set (i.e., dat) will include all the data. The second (i.e., *dat2*) one will drop out data that are from pooled samples (i.e., from adult male + female pooled data) and/or data from adults and progeny that come from different nests. The third one (i.e., *dat3*) will drop out all effect size measures where the PFAS concentration in the adult OR progeny is below the limit of detection/quantification. Eval is false in the following chunks.

```{r, eval=FALSE}
dat2 <-
  dat %>%
  dplyr::filter(data_pooled == "No" & nest == "Yes")

VCV_lnRR_dat2 <- impute_covariance_matrix(dat2$var_lnRR,
                                          cluster = dat2$measurement_ID_A,
                                          r = 0.5)
```

Remove all effect sizes where concentration in the adult OR progeny is below the limit of detection/quantification

```{r, eval=FALSE}
Remove es_IDs where limit_type_A OR limit_type_P is != NA
dat3 <-
  dat2 %>%
  dplyr::filter(if_all(c(limit_type_A, limit_type_P), ~is.na(.)))
```

# Graphics

## Distribution of effect sizes

Plotting effect size measurements distribution

```{r, fig.height=8, fig.width=15, , eval=FALSE}
mean
ggplot(dat, aes(x=lnRR))+ geom_histogram(fill = "salmon", 
                                         col = "black",
                                         binwidth = 0.2) + theme_classic()
# variance
ggplot(dat, aes(x=var_lnRR))+ geom_histogram(fill = "salmon", 
                                             col = "black",
                                             binwidth = 0.05) + theme_classic()
# log variance
ggplot(dat, aes(x=var_lnRR))+ geom_histogram(fill = "salmon", 
                                             col = "black",
                                             binwidth = 0.05) + scale_x_log10()+theme_classic()
```

# Summary

## Table of sample sizes

The following chunk creates a table of effect sizes and variables.

```{r}
table_sample_sizes <- dat %>% 
  dplyr::summarise('studies' = n_distinct(study_ID),
                   'species' = n_distinct(Phylogeny),
                   'pfas type' = n_distinct(pfas_ID),
                   'Adult sample types' = n_distinct(sample_type_A),
                   'Progeny sample types' = n_distinct(sample_type_P),
                   'Breeding stage' = n_distinct(breeding_stage),
                   'Laying order' = n_distinct(laying_order),
                   'Same nest' = n_distinct(nest),
                   'effect sizes' = n_distinct(es_ID),
                   'effect sizes (eggs)' = n_distinct(es_ID[life_stage_P == "egg"]),
                   'studies (eggs)' = n_distinct(study_ID[life_stage_P == "egg"]),
                   'species (eggs)' = n_distinct(Phylogeny[life_stage_P == "egg"]),
                   'effect sizes (chicks)' = n_distinct(es_ID[life_stage_P == "chick"]),
                   'studies (chicks)' = n_distinct(study_ID[life_stage_P == "chick"]),
                   'species (chicks)' = n_distinct(Phylogeny[life_stage_P == "chick"])
                   )

table_sample_sizes <- t(table_sample_sizes)

colnames(table_sample_sizes) <- "n (sample size)"

kable(table_sample_sizes) %>% 
  kable_styling("striped", position="left")

# Save the table as an Excel file
write.table(table_sample_sizes, file = here("RData", "table_sample_sizes.csv"), sep = ",", row.names = TRUE, col.names = TRUE)

# Convert the table to a plot
table_sample_sizes_df <- as.data.frame(table_sample_sizes)

table_sample_sizes_df$variable <- rownames(table_sample_sizes_df)

table_sample_sizes_df <- table_sample_sizes_df %>% 
  dplyr::arrange(variable) %>%
  mutate(variable = reorder(variable, `n (sample size)`))


my_palette <- colorRampPalette(brewer.pal(8, "Dark2"))(length(table_sample_sizes_df$variable))

ggplot(table_sample_sizes_df, aes(x=variable,
                                  y=`n (sample size)`, fill=variable)) +
  geom_col() +
  geom_text(aes(label = `n (sample size)`),
            position = position_stack(vjust = 0.5),
            size = 4) +
  coord_flip() +
  ggtitle("Sample sizes") +
  theme_light() +
  scale_fill_manual(values = my_palette, guide = guide_legend(reverse = TRUE))


# Save the table
#ggsave(here("RData", "table_sample_sizes.png"), width = 10, height = 7)

```

## Summary of the dataset

The following chunk creates a table of summary of the dataset

```{r}
table_summary_dataset <- kable(summary(dat), format = "html") %>% 
  kable_styling("striped", position = "left") %>% 
  scroll_box(width = "100%", height = "500px") #%>%
  #write_file(here("RData", "table_summary_dataset.html")) # Save the table as an HTML file
```

# FIRST AIM: to estimate the overall effect

# Choosing a meta-analytic model

Now that we calculated the effect sizes and sampling variances, we can use them to achieve the first goal of our meta-analysis, which is *estimating the overall effect*.

One common challenge in environmental meta-analysis is dealing with non-independence among data points (i.e., effect sizes), as each study may contribute multiple effect sizes. A multilevel model is the simplest meta-analytic model for addressing this issue in environmental science research. Our dataset has N = 13 primary studies with k = 371 effect sizes. k/N = 28 indicating statistical dependence. This is because, on average, 18 effect sizes are contributed by each primary study. Failing to deal with *statistical non-independence* will inflate the Type 1 error, leading to an underestimated standard error of Î²0 and a spurious p-value of Î²0. Non-independence among effect sizes must be taken into account from the start of the analysis. To properly structure the data to account for non-independence, we need to create a unique identifier for each primary study (Study_ID: S1, S2, S3, etc.) and a unique identifier for each effect size (ES_ID: ES1, ES2, ES3, etc.). With these variables included in the data file, we can use the function rma.mv (instead of rma) to fit the *multilevel meta-analytic model*.

## Determine the random effect structure

The random effects model is used to account for between-study heterogeneity, which is the variability in effect sizes among the studies being analyzed. When determining the random effect structure, we are trying to identify the sources of this heterogeneity and to quantify the degree to which it is present in the data.

```{r, eval=FALSE}
ma_all_random_effects <- rma.mv(yi = lnRR,
                                V = VCV_lnRR, # Add `VCV_lnRR` to account for correlated errors
             random = list(~1|study_ID, # Between-study effect
                           ~1|Phylogeny, # Phylogenetic correlation between species
                           ~1|species_ID, # Between species effect
                           ~1|pfas_ID, # Between type of PFAS effect
                           ~1|es_ID # Within-study effect
              ),
             R = list(Phylogeny = cor_tree),
             test = "t",
             data = dat)

save(ma_all_random_effects, file = here("Rdata", "ma_all_random_effects.RData"))
```

```{r}
load(here("RData", "ma_all_random_effects.RData"))
summary(ma_all_random_effects)
orchard_plot(ma_all_random_effects,
             group = "study_ID", 
             data = dat, 
             xlab = "lnRR")
```

From previous graph we can see that overall estimate from a random-effects meta-analysis of 371 effect sizes is centered on zero, with a 95% CI that spans the line of no-effect.

```{r}
summary(ma_all_random_effects)
i2_ml(ma_all_random_effects)
```

*Phylogeny* does not explain for any variance. (sigma squared = 0.0000) *Species_ID* does not explain for any variance. (sigma squared = 0.0000)

Thus, we remove them from the model.

The effects of the other grouping variables are assumed to be random and are accounted for in the analysis. This allows the model to account for any differences between the groups and to provide more accurate estimates of the relationships between the variables.

## Intercept meta-analytical model

In a meta-analysis, an intercept model is a statistical model that is used to estimate the overall effect size of a treatment or intervention. The intercept represents the expected value of the outcome variable when all predictor variables are set to zero. In other words, it represents the baseline or control group in the study. The intercept is often used to compare the effect of the treatment or intervention to the control group, and it is typically estimated using a weighted average of the effect sizes from individual studies included in the meta-analysis. The intercept model can be used to assess the overall effectiveness of an intervention and to identify factors that may influence the magnitude of the treatment effect.

```{r, eval=FALSE}
ma_model <- rma.mv(yi = lnRR,
             V = VCV_lnRR, 
             random = list(~1|study_ID,
                           ~1|pfas_ID,
                           ~1|es_ID
              ),
             test = "t",
             data = dat)

save(ma_model, file = here("Rdata", "ma_model.RData"))
```

```{r}
load(here("RData", "ma_model.RData"))
summary(ma_model)
orchard_plot(ma_model,
             mod = "1",
             group = "study_ID", 
             data = dat, 
             xlab = "lnRR",
             alpha = 0.4,
             trunk.size=9,
             branch.size = 2) +  
           scale_colour_manual(values = "darkorange")+ # change colours
           scale_fill_manual(values="darkorange")+ 
           scale_size_continuous(range = c(1, 7))+ # change point scaling
           theme(panel.border = element_rect(colour = "black", 
                                             fill=NA,
                                             size=1.3), # border around the plot
                 text = element_text(size = 18), # change font sizes
                 legend.title = element_text(size = 15),
                 legend.text = element_text(size = 13))
```

### Forest plot of effect size measurements

Forest plot showing the effect sizes from each study (and their 95% CIs) and the overall effect based on model.

```{r create the forest plot, eval=FALSE}
forest(ma_model, # rma.mv object
       xlab = "Effect size lnRR")
```

# SECOND AIM: to assess the heterogeneity/consistency among studies

The second goal of a meta-analysis is to assess the consistency (or heterogeneity) among studies.

# Percentage of heterogeneity

We can use I2 statistic to express variance due to differences between studies (not due to sampling variance) in the case of random-effects model.

Use i2_ml function to obtain the total I\^2. The I\^2 statistic (J. P. Higgins and Thompson 2002) quantifies between-study heterogeneity. It is defined as the percentage of variability in the effect sizes that is not caused by sampling error. I\^2 draws on the assumption that Q follows a Ï‡\^2 distribution with Kâˆ’1 degrees of freedom under the null hypothesis of no heterogeneity. It is calculated as the percentage of total variation in effect sizes that is due to between-study heterogeneity, rather than sampling error within each study. More info here: <https://bookdown.org/MathiasHarrer/Doing_Meta_Analysis_in_R/heterogeneity.html>

```{r}
I2 <- orchaRd::i2_ml(ma_model)
i2_ml(ma_model)

orchaRd::orchard_plot(ma_model,
                      mod="1",
                      group = "study_ID",
                      data = dat,
                      xlab = "lnRR") + 
  annotate(geom="text",
           x= 0.80,
           y= 1, 
           label= paste0("italic(I)^{2} == ", round(I2[1],4)),
           color="black",
           parse = TRUE, 
           size = 5) +
  scale_fill_manual(values="grey") +
  scale_colour_manual(values="grey")
```

I\^2 = 99.001. It means that 99% of the total variation in effect sizes is due to between-study heterogeneity, indicating a high level of heterogeneity among the studies included in the analysis. We see there is a small between-study heterogeneity (indicated by I2_study_ID), a small between-PFAS types heterogeneity (indicated by I2_pfas_ID) while a very large within-study heterogeneity (indicated by I2_es_ID).

# THIRD AIM: to explain the heterogeneity

The third aim of a meta-analysis is to explain the heterogeneity.

# Single-moderator meta-regressions

Now that the effects of the grouping variables are modeled as random effects, we include in the model additional variables (moderators/predictors) to explain heterogeneity among effect sizes (i.e., meta-regression). Moderators are tested for their overall effect on the maternal PFAS transfer. The moderators I am going to include in the model are:

-   type of progeny's tissue
-   type of adult's tissue
-   PFAS carbon chain length
-   PFAS molecular weight
-   Seabirds vs non-seabirds
-   ...
-   ...
-   ...

## Function to run all models with the same structure

```{r}
run_model <- function(data, formula){
  data <- as.data.frame(data) # convert data set into a data frame to calculate VCV matrix 
  VCV <- impute_covariance_matrix(data$var_lnRR,
                                     cluster = data$measurement_ID_A, 
                                     r = 0.5) # create VCV matrix for the specified data
  rma.mv(lnRR, VCV, # run the model, as described earlier
         mods = formula,
         random = list(~1|study_ID,
                       ~1|pfas_ID,
                       ~1|es_ID),
         test = "t",
         data = data,
         sparse = TRUE)
}
```

## Functions to run plots with the same structure

```{r}
# plot_continuous <- function(data, 
#                             model,
#                             moderator,
#                             xlab){
# 
# pred <- predict.rma(model)
# 
# data %>% mutate(fit=pred$pred, 
#                ci.lb=pred$ci.lb,
#                ci.ub=pred$ci.ub,
#                pr.lb=pred$cr.lb,
#                pr.ub=pred$cr.ub) %>% # Add confidence intervals, mean predictions and prediction intervals
# ggplot(aes(x = moderator, 
#            y = lnRR)) +
#      geom_ribbon(aes(ymin = pr.lb, 
#                      ymax = pr.ub, 
#                      color = NULL), 
#                  alpha = .075) + # Shaded area for prediction intervals
#      geom_ribbon(aes(ymin = ci.lb,
#                      ymax = ci.ub,
#                      color = NULL), 
#                  alpha = .2) + # Shaded area for confidence intervals
#      geom_point(aes(size=(1/sqrt(VCV_lnRR))), 
#                     #fill=Cooking_Category),
#                 shape=21,
#                 alpha=0.8) + # Points scaled by precision
#      scale_fill_manual(values=c("#55C667FF",
#                                            "goldenrod2",
#                                            "dodgerblue3"))+
#      geom_line(aes(y = fit), 
#                size = 1.5)+  # Regression line
#   labs(x = xlab, y = "lnRR", 
#        size = "Precison (1/SE)") +
#   theme_bw() +
#   scale_size_continuous(range=c(1,9))+ # Point scaling
#   geom_hline(yintercept = 0,
#              linetype = 2,
#              colour = "black",
#              alpha=0.5)+   # horizontal line at lnRR = 0
#   theme(text = element_text(size = 18,
#                             colour = "black",
#                             hjust = 0.5), # change font sizes and legend position
#           legend.text=element_text(size=14),
#           legend.position=c(0,0), 
#           legend.justification = c(0,0),
#           legend.background = element_blank(), 
#           legend.direction="horizontal",
#           legend.title = element_text(size=15), 
#           panel.border=element_rect(colour="black", fill=NA, size=1.2))
# }
```

## Single-moderator models

Note: All continuous variables were z-transformed.

### Sample type progeny

```{r, eval=FALSE}
sample_type_p_model <- run_model(dat, ~sample_type_P)

save(sample_type_p_model, file = here("Rdata", "sample_type_p_model.RData"))
```

```{r}
load(here("RData", "sample_type_p_model.RData"))
summary(sample_type_p_model)
#r2_ml(sample_type_p_model, dat, boot = 10)
#                Est.  2.5% 97.5%                                                                                          
# R2_marginal    0.62 0.546 0.675
# R2_conditional 0.79 0.773 0.823
```

Make same plot but with albumen and others

```{r}
dat$albumen <- ifelse(dat$sample_type_P == "albumen", "albumen", "others")
```

```{r, eval=FALSE}
albumen_model <- run_model(dat, ~albumen)

save(albumen_model, file = here("Rdata", "albumen_model.RData"))
```

```{r}
load(here("RData", "albumen_model.RData"))
summary(albumen_model)

orchard_plot(albumen_model,
             mod = "albumen", 
             xlab = "lnRR", 
             alpha = 0.4, 
             data = dat,
             group = "study_ID",
             trunk.size = 9,
             branch.size = 2) +  
           scale_colour_manual(values = c("#55C667FF",
                                                     "goldenrod2", 
                                                     "dodgerblue3",
                                                     "firebrick1",
                                                     "darkslateblue"))+ # change colours
           scale_fill_manual(values=c("#55C667FF",
                                                 "goldenrod2",
                                                 "dodgerblue3",
                                                 "firebrick1",
                                                 "darkslateblue"))+ 
           scale_size_continuous(range = c(1, 7))+ # change point scaling
           theme(panel.border = element_rect(colour = "black",
                                             fill=NA, 
                                             size=1.3), # border around the plot
                 text = element_text(size = 24), # change font sizes
                 legend.title = element_text(size = 15),
                 legend.text = element_text(size = 13))
```

### Sample type adult

```{r, eval=FALSE}
sample_type_a_model <- run_model(dat, ~sample_type_A)

save(sample_type_a_model, file = here("Rdata", "sample_type_a_model.RData"))
```

```{r, eval=FALSE}
load(here("RData", "sample_type_a_model.RData"))
summary(sample_type_a_model)
#r2_ml(sample_type_a_model, dat, boot = 10)
#                 Est.  2.5% 97.5%                                                                                         
# R2_marginal    0.135 0.089 0.155
# R2_conditional 0.213 0.146 0.326

orchard_plot(sample_type_a_model,
             mod = "sample_type_A",
             group = "study_ID", 
             data = dat,
             xlab = "lnRR")
```

### PFAS carbon chain length

```{r, eval=FALSE}
sum(is.na(dat$carbon_chain_length))
#[1] 65
dat_ccc <- dat[complete.cases(dat[ , "carbon_chain_length"]),]
sum(is.na(dat_ccc$carbon_chain_length))
#[1] 0
ccl_model <- run_model(dat_ccc, ~scale(carbon_chain_length))

save(ccl_model, file = here("Rdata", "ccl_model.RData"))
```

```{r}
load(here("RData", "ccl_model.RData"))
summary(ccl_model)
#r2_ml(ccl_model, dat_ccc, boot = 10)
#                 Est.  2.5% 97.5%                                                                                         
# R2_marginal    0.039 0.004 0.065
# R2_conditional 0.097 0.029 0.137

bubble_plot(ccl_model,
            mod = "carbon_chain_length",
            group = "study_ID", 
            data = dat_ccc, 
            xlab = "carbon_chain_length")
```

Filtering out albumen

```{r}
dat_no_alb <- 
  dat %>% 
  dplyr::filter(sample_type_P != "albumen")
```

```{r, eval = FALSE}
ccl_model_no_alb <- run_model(dat_no_alb, ~ carbon_chain_length)

save(ccl_model_no_alb, file = here("Rdata", "ccl_model_no_alb.RData"))
```

```{r}
load(here("RData", "ccl_model_no_alb.RData"))
summary(ccl_model_no_alb)
i2_ml(ccl_model_no_alb)
bubble_plot(ccl_model_no_alb, 
            mod = "carbon_chain_length",
            group = "study_ID", 
            data = dat_no_alb,
            xlab = "carbon_chain_length")
```

### PFAS molecular weight

```{r, eval=FALSE}
mw_model <- run_model(dat, ~scale(molecular_weight))

save(mw_model, file = here("Rdata", "mw_model.RData"))
```

```{r}
load(here("RData", "mw_model.RData"))
summary(mw_model)

bubble_plot(mw_model, 
            mod = "molecular_weight", 
            group = "study_ID",
            data =dat,
            xlab = "molecular_weight")

# Pearson's correlation
cor.test(dat$carbon_chain_length, dat$molecular_weight) #extremely highly correlated (cor=0.9515476)
```

### Functional group

```{r, eval=FALSE}
sum(is.na(dat$functional_group))
#[1] 1
dat_fg <- dat[complete.cases(dat[ , "functional_group"]),]
sum(is.na(dat_fg$functional_group))
#[1] 0

fun_gro_model <- run_model(dat_fg, ~ functional_group - 1)

save(fun_gro_model, file = here("Rdata", "fun_gro_model.RData"))
```

```{r}
load(here("RData", "fun_gro_model.RData"))
summary(fun_gro_model)
#r2_ml(fun_gro_model, dat_fg, boot = 10)
#                 Est.  2.5% 97.5%                                                                                         
# R2_marginal    0.018 0.006 0.039
# R2_conditional 0.069 0.030 0.117

orchard_plot(fun_gro_model,
             mod = "functional_group",
             group = "study_ID",
             data =dat_fg, 
             xlab = "lnRR",
             angle = 45)

#TODO

# test1 <- run_model(dat, ~ functional_group)
# summary(test1)
# 
# test2 <- run_model(dat, ~ relevel(factor(functional_group), ref = "mixed"))
# summary(test2)
# 
# 
# library(multicomp)
# 
# contrasts <- glht(test1)

```

### Diet

```{r, eval=FALSE}
diet_model <- run_model(dat, ~ diet)

save(diet_model, file = here("Rdata", "diet_model.RData"))
```

```{r}
load(here("RData", "diet_model.RData"))
summary(diet_model)
#r2_ml(diet_model, dat, boot = 10)
#                 Est.  2.5% 97.5%                                                                                         
# R2_marginal    0.061 0.034 0.088
# R2_conditional 0.091 0.040 0.143

orchard_plot(diet_model,
             mod = "diet",
             group = "study_ID",
             data =dat, 
             xlab = "lnRR",
             angle = 45)
```

### Main food item

```{r, eval=FALSE}
food_model <- run_model(dat, ~ main_food_type)

save(food_model, file = here("Rdata", "food_model.RData"))
```

```{r}
load(here("RData", "food_model.RData"))
summary(food_model)

orchard_plot(food_model,
             mod = "main_food_type",
             group = "study_ID",
             data =dat, 
             xlab = "lnRR",
             angle = 45)
```

diet_model: Test of Moderators p-val = 0.0016 food_model: Test of Moderators p-val = 0.0059

Thus, only diet added as moderator in the full model.

### Bird's body weight

```{r, eval=FALSE}
body_weight_model <- run_model(dat, ~ body_weight_mean)

save(body_weight_model, file = here("Rdata", "body_weight_model.RData"))
```

```{r}
load(here("RData", "body_weight_model.RData"))
summary(body_weight_model)
#r2_ml(body_weight_model, dat, boot = 10)
#                 Est.  2.5% 97.5%                                                                                         
# R2_marginal    0.005 0.000 0.018
# R2_conditional 0.066 0.036 0.102

bubble_plot(body_weight_model,
             mod = "body_weight_mean",
             group = "study_ID",
             data = dat, 
             xlab = "body_weight_mean")
```

### Clutch size

```{r, eval=FALSE}
clutch_size_model <- run_model(dat, ~ clutch_size)

save(clutch_size_model, file = here("Rdata", "clutch_size_model.RData"))
```

```{r}
load(here("RData", "clutch_size_model.RData"))
summary(clutch_size_model)
#r2_ml(clutch_size_model, dat, boot = 10)
#                 Est.  2.5% 97.5%                                                                                         
# R2_marginal    0.034 0.015 0.060
# R2_conditional 0.060 0.037 0.091

bubble_plot(clutch_size_model,
             mod = "clutch_size",
             group = "study_ID",
             data = dat, 
             xlab = "clutch_size")
```

### Egg weight

```{r, eval=FALSE}
sum(is.na(dat$egg_weight_mean))
#[1] 67
dat_egg_weight <- dat[complete.cases(dat[ , "egg_weight_mean"]),]
sum(is.na(dat_egg_weight$egg_weight_mean))
#[1] 0
egg_weight_model <- run_model(dat_egg_weight, ~ egg_weight_mean)

save(egg_weight_model, file = here("Rdata", "egg_weight_model.RData"))
```

```{r}
load(here("RData", "egg_weight_model.RData"))
summary(egg_weight_model)
#r2_ml(egg_weight_model, dat_egg_weight, boot = 10)
#                 Est.  2.5% 97.5%                                                                                         
# R2_marginal    0.003 0.000 0.026
# R2_conditional 0.064 0.025 0.168

bubble_plot(egg_weight_model,
             mod = "egg_weight_mean",
             group = "study_ID",
             data = dat_egg_weight, 
             xlab = "egg_weight_mean")
```

### Laying order

```{r, eval=FALSE}
sum(is.na(dat$laying_order)) #checking the number of NAs
#[1] 315
laying_order_model <- run_model(dat, ~scale(laying_order))

save(laying_order_model, file = here("Rdata", "laying_order_model.RData"))
```

```{r}
load(here("RData", "laying_order_model.RData"))
summary(laying_order_model)
bubble_plot(laying_order_model,
             mod = "laying_order",
             group = "study_ID",
             data = dat, 
             xlab = "laying_order")
#laying order has many NAs. Thus, it won't be added to the full model.
```

### Life stage progeny

```{r, eval=FALSE}
life_stage_model <- run_model(dat, ~ life_stage_P)

save(life_stage_model, file = here("Rdata", "life_stage_model.RData"))
```

```{r}
load(here("RData", "life_stage_model.RData"))
summary(life_stage_model)
#r2_ml(life_stage_model, dat, boot = 10)
#                 Est.  2.5% 97.5%                                                                                         
# R2_marginal    0.007 0.000 0.027
# R2_conditional 0.086 0.022 0.145

orchard_plot(life_stage_model,
             mod = "life_stage_P",
             group = "study_ID",
             data =dat, 
             xlab = "lnRR",
             angle = 45)
```

## Mulit-moderator models

### Albumen \* Carbon chain length

```{r}
dat$albumen <- ifelse(dat$sample_type_P == "albumen", "albumen", "others")
```

```{r, eval = FALSE}

#dat$z_carbon_chain_length <- scale(dat$carbon_chain_length)
mmr_model1 <- run_model(dat, ~ albumen * scale(carbon_chain_length))

save(mmr_model1, file = here("Rdata", "mmr_model1.RData"))
```

```{r}
load(here("RData", "mmr_model1.RData"))
summary(mmr_model1)

orchard_plot(mmr_model1,
             mod = "albumen",
             group = "study_ID",
             data = dat, 
             xlab = "lnRR",
             at = list(carbon_chain_length = c(6, 12, 16)),
             by = "carbon_chain_length" )

bubble_plot(mmr_model1,
             mod = "carbon_chain_length",
             group = "study_ID",
             data =dat, 
             ylab = "lnRR", 
             xlab = "Carbon chain length",
             by = "albumen",
            g = TRUE)
```

### Functional group + Carbon chain length

```{r, eval=FALSE}
mmr_model2 <- run_model(dat, ~ functional_group + scale(carbon_chain_length))

save(mmr_model2, file = here("Rdata", "mmr_model2.RData"))
```

```{r}
load(here("RData", "mmr_model2.RData"))
summary(mmr_model2)

orchard_plot(mmr_model2,
             mod = "functional_group",
             group = "study_ID",
             data = dat,
             xlab = "lnRR",
             at = list(carbon_chain_length = c(6, 12, 16)),
             by = "carbon_chain_length" )
```

### Seabirds + Carbon chain length

```{r, eval=FALSE}
mmr_sea_ccl <- run_model(dat, ~ seabird + scale(carbon_chain_length))

save(mmr_sea_ccl, file = here("Rdata", "mmr_sea_ccl.RData"))
```

```{r}
load(here("RData", "mmr_sea_ccl.RData"))
summary(mmr_sea_ccl)

orchard_plot(mmr_sea_ccl,
             mod = "seabird",
             group = "study_ID",
             data = dat,
             xlab = "lnRR",
             at = list(carbon_chain_length = c(6, 12, 16)),
             by = "carbon_chain_length" )
```

### Laying order + Carbon chain length

```{r, eval=FALSE}
mmr_lay_ccl <- run_model(dat, ~ laying_order + scale(carbon_chain_length) )

save(mmr_lay_ccl, file = here("Rdata", "mmr_lay_ccl.RData"))
```

```{r}
load(here("RData", "mmr_lay_ccl.RData"))
summary(mmr_lay_ccl)

orchard_plot(mmr_lay_ccl,
             mod = "laying_order",
             group = "study_ID",
             data = dat,
             xlab = "lnRR",
             at = list(carbon_chain_length = c(6, 12, 16)),
             by = "carbon_chain_length" )

# TODO
# test4 <- run_model(dat, ~ laying_order*scale(carbon_chain_length) )
# 
# summary(test4)

```

### Sample types

```{r, eval = FALSE}
mmr_model3 <- run_model(dat, ~ sample_type_A + sample_type_P)

save(mmr_model3, file = here("Rdata", "mmr_model3.RData"))
```

```{r}
load(here("RData", "mmr_model3.RData"))
summary(mmr_model3)

ggplot(data = dat, aes(x = sample_type_A, 
                       y = lnRR)) +
  geom_boxplot() +
  facet_wrap(~ sample_type_P)

orchard_plot(mmr_model3,
             mod = "sample_type_A",
             group = "study_ID",
             data = dat,
             xlab = "lnRR",
             by = "sample_type_P" )
```

# Full model

Mixed-effects meta-regression model

```{r, eval=FALSE}
full_model0 <- rma.mv(yi = lnRR,
                      V = VCV_lnRR, 
                      mods = ~1 + 
                        functional_group +
                        scale(carbon_chain_length) +
                        sample_type_A +
                        sample_type_P +
                        scale(clutch_size) +
                        scale(body_weight_mean) +
                        scale(egg_weight_mean) +
                        diet +
                        life_stage_P,
                      random = list(~1|study_ID,
                                    ~1|pfas_ID, 
                                    ~1|es_ID
                                    ),
                      test = "t",
                      data = dat,
                      sparse = TRUE)

save(full_model0, file = here("Rdata", "full_model0.RData"))
```

```{r}
load(here("RData", "full_model0.RData"))
summary(full_model0)
```

# Model selection

Rephrased From: <https://itchyshin.github.io/Meta-analysis_tutorial/>

Model selection is a powerful method to:

-   *quantify the importance of moderators* in explaining heterogeneity, which is useful when look for, for example, global drivers of environmental changes;

-   *multimodel inference*, which can make model inferences about the moderators in the context of models with all possible combinations of moderators rather than a single 'best' model;

-   *multimodel predictions*, which can predict (average) effects of a moderator and its CIs based on models with all possible combinations of moderators rather than a single 'best' model.

We performed model selection using an information-theoretic approach with the help of the metafor package and other specialized packages such as MuMIn or glmulti. We will specifically be using the MuMIn package due to its simpler syntax. It is important to note that while using R2 for model selection is a viable option, it is not the preferred method in this case."

**Important point**: when conducting a meta-analysis, it is important to carefully choose the moderators based on their prior plausibility and the predefined research questions you are trying to address. It is not recommended to include a large number of moderators or to remove them until you obtain a significant model.

## Best model

By 'best model', we mean the acceptable amount of information loss when we use a fitted model to approximate the real data generating mechanism. When we refer to the "best model," we are referring to the model that has the least amount of information loss when approximating the actual data generating process. To identify the best model, we first fit a multilevel multi-moderator meta-analytic model with all plausible moderators (referred to as the full model). We then use maximum likelihood (ML) to produce models with all possible combinations of moderators from the full model. This process is known as **dredging**.

```{r, eval=FALSE}
eval(metafor:::.MuMIn) # use eval() function to extract helper functions from MuMIn and make them usable in metafor.
mod.candidate <- dredge(full_model0, beta = "none", evaluate = TRUE, rank = "AICc", trace=2) # dredge to produce all possible models

# Save the candidate best model
save(mod.candidate, file = here("Rdata", "best_model.RData"))
```

```{r, eval=FALSE}
# Next step, letâ€™s select a sets of best model. This can be done by using thumb of rules, for example, delta AICc <= 4:
subset(mod.candidate, delta <= 4, recalc.weights = FALSE)
# Sum of weights for each variable included in the mod.candidate
```

```{r}
load(here("RData", "best_model.RData"))

sw(mod.candidate)

weights <- read_csv(here("Data", "sum_of_weights_AIC.csv"))

weights <- weights %>% 
  mutate(weights_percentage = round( Sum_of_weights * 100))

weights$Predictor <- factor(weights$Predictor, levels = weights$Predictor[order(weights$weights_percentage, weights$R2_conditional)])
```

R-squared conditional is more appropriate the R-squared marginal for comparing different models that have the same set of predictor variables and here we are comparing the R-squared of single-moderator meta-regression models that have the same random structure but a different moderator.
This is because R-squared conditional measures the strength of the relationship between the dependent and independent variables, given that the other variables are already included in the model. By using R-squared conditional, you can compare the relative strength of the relationships between the dependent variable and the independent variables in each of the models, taking into account the other variables that are included in both models.

Plot
```{r}

AIC_weights <- ggplot(weights, aes(Predictor, Sum_of_weights)) +
  geom_col(aes(fill = ""), width = 0.7) +
  geom_text(aes(label = paste0(weights_percentage, "%"), x = Predictor), 
            position = position_stack(vjust = 0.5), 
            size = 3) +
  geom_text(aes(label = paste("R2 =", sprintf("%.3f", R2_conditional)), x = Predictor, y =  max(Sum_of_weights)), #R2 conditional 
            position = position_stack(vjust = 1.07), 
            size = 3, color = "red") +
  theme_light() +
  coord_flip() +
  scale_fill_manual(values = c("#999999")) +
  scale_x_discrete(name = "Predictor") +
  scale_y_continuous(name = "AIC weights",
                     breaks = seq(0, 1, by = 0.2)) +
  theme(legend.position = "none",
        axis.title.x = element_text(size = 8.5),
        axis.title.y = element_text(size = 8.5),
        axis.text = element_text(size = 8),
        panel.grid.major = element_line(color = "grey", 
                                       linewidth  = 0.2, 
                                       linetype = "dashed"),
       panel.grid.minor = element_line(color = "grey", 
                                      linewidth  = 0.2, 
                                      linetype = "dotted"))
AIC_weights

# ggsave(here("RData", "AIC_weights.png"),
#        width = 8.5,
#        height = 6)

# weights <- weights %>% 
#   arrange(desc(weights_percentage), desc(R2_conditional))
# 
# weights$Predictor <- factor(weights$Predictor, levels = weights$Predictor[order(weights$weights_percentage, weights$R2_conditional)])
# 
# R2 <- ggplot(weights, aes(Predictor, R2_conditional)) +
#   geom_col(aes(fill = ""), width = 0.7) +
#   geom_text(aes(label = paste("Weight =", sprintf("%.2f", Sum_of_weights)), x = Predictor, y =  max(R2_conditional)), 
#             position = position_stack(vjust = 1.1), 
#             size = 3, color = "red") +
#   theme_light() +
#   coord_flip() +
#   scale_fill_manual(values = c("#999999")) +
#   scale_x_discrete(name = "Predictor") +
#   scale_y_continuous(name = "R-squared",
#                      breaks = seq(0, 0.7, by = 0.1)) +
#   theme(legend.position = "none",
#         axis.title.x = element_text(size = 8.5),
#         axis.title.y = element_text(size = 8.5),
#         axis.text = element_text(size = 8),
#         panel.grid.major = element_line(color = "grey", 
#                                        linewidth  = 0.2, 
#                                        linetype = "dashed"),
#        panel.grid.minor = element_line(color = "grey", 
#                                       linewidth  = 0.2, 
#                                       linetype = "dotted"))
# R2

# ggsave(here("RData", "R2.png"),
#        width = 10,
#        height = 6)
```

The model selection table shows the results of model selection based on the AICc criterion.

The model with the best AICc is the one at the top of the table, which has the lowest AICc and the highest weight:

| Global model call: rma.mv(yi = lnRR, V = VCV_lnRR, mods = \~1 + functional_group + scale(carbon_chain_length) + sample_type_A + sample_type_P, random = list(\~1 \| study_ID, \~1 \| pfas_ID, \~1 \| es_ID), data = dat, test = "t", sparse = TRUE) \-\-- Model selection table (Int) fnc_grp smp_typ_A smp_typ_P scl(crb_chn_lng) df logLik AICc delta weight 16 + + + + 0.3964 19 -479.083 998.8 0 0.948 Models ranked by AICc(x)

All the variables (labeled "fnc_grp", "smp_typ_A", "smp_typ_P" and "crb_chn_lng") are included as predictors in the best model according to the AICc criterion. These variables are used as predictor in the model with the aim to explain the variation in the outcome variable, lnRR. The column labeled "scl(crb_chn_lng)" shows the scaling factor applied to the variable "carbon_chain_length" random effects term, so it means the variable "carbon_chain_length" is included in the model and it's random effects term has been scaled by 0.3964.

# Conditional analyses

# Publication bias

Publication bias is the phenomenon where studies with certain characteristics, such as small sample size, are more likely to be published.

## Small study effect

One form of publication bias is the small study effect, where smaller studies tend to report larger treatment effects than larger studies. To detect this, one way is to examine the relationship between effect size and its uncertainty by adding the uncertainty as a moderator variable. This will allow to quantify the correlation between the effect size and its uncertainty.

```{r, eval=FALSE}
MLMR_mod_ess.se <- rma.mv(yi = lnRR, 
                               V = VCV_lnRR, 
                               mods = ~ ess.se, # add adjusted based sampling error - tilde square root n as a moderator to test small study effect (see section "lnRR and variance calculations).
                               random = list(~1|study_ID,
                                          ~1|pfas_ID, 
                                          ~1|es_ID
                                          ), 
                               method = "REML", 
                               test = "t", 
                               data = dat
                               )
save(MLMR_mod_ess.se, file = here("Rdata", "MLMR_mod_ess.se.RData"))
```

```{r}
load(here("RData", "MLMR_mod_ess.se.RData"))
summary(MLMR_mod_ess.se)
```

If we look at ess.se given under Model Results: p-value and 95% CIs suggest that there is no statistical relationship between the effect size its error, meaning that no small study effect exits.

## Time-lag bias

```{r, eval = FALSE}
MLMR_mod_year.c <- metafor::rma.mv(lnRR,
                            VCV_lnRR,
                            mods = ~ scale(year_publication),
                            random = list(~1|study_ID,
                                          ~1|pfas_ID, 
                                          ~1|es_ID
                                          ),
                            data = dat)
save(MLMR_mod_year.c, file = here("Rdata", "MLMR_mod_year.c.RData"))
```

```{r}
load(here("RData", "MLMR_mod_year.c.RData"))
summary(MLMR_mod_year.c)
pb_bubble <- orchaRd::mod_results(MLMR_mod_year.c,
                                  mod = "year_publication",
                                  group = "study_ID",
                                  data = dat)

orchaRd::bubble_plot(pb_bubble, 
                     data = dat,
                     group = "study_ID",
                     mod = "year_publication",
                     xlab = "Year", 
                     legend.pos = "top.left")
```

If we look at ess.se given under Model Results: p-value and 95% CIs suggest that there is no statistical relationship between the effect size its error, meaning that no time-lag bias exits.

# Sensitivity analysis - Models

-   Run a sensitivity analysis with and without the effect sizes that fail Geary's test.

```{r}

```

-   Run a sensitivity analysis without pooled data (male+female) and adult and progeny from different nests (i.e., dat2)

Meta-analytic model

```{r, eval=FALSE}
dat2_model <- rma.mv(yi = lnRR,
             V = VCV_lnRR_dat2 , 
             random = list(~1|study_ID, 
                            ~1|Phylogeny, 
                            ~1|species_ID, 
                            ~1|pfas_ID,
                            ~1|es_ID
                           ),
             R = list(Phylogeny = cor_tree),
             test = "t",
             data = dat2)

save(dat2_model, file = here("Rdata", "dat2_model.RData"))
```

```{r, eval=FALSE}
load(here("RData", "dat2_model.RData"))
summary(dat2_model)
i2_ml(dat2_model)
orchard_plot(dat2_model,
             group = "study_ID", 
             data = dat2, 
             xlab = "lnRR")
```
